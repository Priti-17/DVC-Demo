{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv(r\"C:\\Users\\plahare\\Downloads\\Numora_Demo\\archive (2)\\train.csv\", sep=\";\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\plahare\\Downloads\\Numora_Demo\\archive (2)\\test.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'y': 'deposit'}, inplace=True)\n",
    "test_df.rename(columns={'y': 'deposit'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the null values\n",
    "train_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_to_onehot = ['job','marital','contact','poutcome']\n",
    "categorial_to_labelencoder = [\"education\",\"housing\",\"deposit\",\"default\",\"loan\",\"month\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_df.copy()\n",
    "# Encode categorical features using OneHotEncoder\n",
    "# convert categorical data into one-hot encoded representation\n",
    "for i in categorial_to_onehot:\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(new_df[[i]])\n",
    "    onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out([i]))\n",
    "    \n",
    "    new_df = pd.concat([new_df, onehot_encoded_df], axis=1)\n",
    "\n",
    "train_df = new_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features using LabelEncoder\n",
    "# convert categorical data into numerical labels\n",
    "encoder = LabelEncoder()\n",
    "for categorial_label in categorial_to_labelencoder:\n",
    "    train_df[categorial_label] = encoder.fit_transform(train_df[categorial_label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['job', 'marital', 'contact', 'poutcome']\n",
    "\n",
    "# Create new_data by dropping the specified columns\n",
    "train_df = train_df.drop(columns_to_drop, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features using OneHotEncoder\n",
    "# convert categorical data into one-hot encoded representation\n",
    "for i in categorial_to_onehot:\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(test_df[[i]])\n",
    "    onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out([i]))\n",
    "    \n",
    "    test_df = pd.concat([test_df, onehot_encoded_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features using LabelEncoder\n",
    "# convert categorical data into numerical labels\n",
    "encoder = LabelEncoder()\n",
    "for categorial_label in categorial_to_labelencoder:\n",
    "    test_df[categorial_label] = encoder.fit_transform(test_df[categorial_label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['job', 'marital', 'contact', 'poutcome']\n",
    "\n",
    "# Create new_data by dropping the specified columns\n",
    "test_df = test_df.drop(columns_to_drop, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical features\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original  dataset: (45211, 35)\n",
      "Shape of cleaned dataset: (40210, 35)\n",
      "we loss: 11.06% from the data\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "# CREAT FUNCTION\n",
    "def remove_outliers(data, numerical_features, threshold=3):\n",
    "\n",
    "    z_scores = data[numerical_features].apply(zscore)\n",
    "    outlier_indices = (z_scores > threshold).any(axis=1)\n",
    "    cleaned_df = data[~outlier_indices]\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "# Usage example:\n",
    "cleaned_df = remove_outliers(train_df, numerical_features)\n",
    "print(\"Shape of original  dataset:\", train_df.shape)\n",
    "print(\"Shape of cleaned dataset:\", cleaned_df.shape)\n",
    "prc = ((train_df.shape[0] - cleaned_df.shape[0]) /train_df.shape[0]) *100\n",
    "print(f'we loss: {round(prc,2)}% from the data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variable\n",
    "X = train_df[['age', 'education', 'default', 'balance', 'housing', 'loan', 'day',\n",
    "       'month', 'duration', 'campaign', 'pdays', 'previous',\n",
    "       'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
    "       'marital_divorced', 'marital_married', 'marital_single',\n",
    "       'contact_cellular', 'contact_telephone', 'contact_unknown',\n",
    "       'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
    "       'poutcome_unknown']]\n",
    "y = train_df['deposit'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled= scaler.fit_transform(X_train[numerical_features])\n",
    "X_test_scaled= scaler.transform(X_test[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest model\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_random_forest = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(f'Random Forest Accuracy: {accuracy_random_forest:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Gradient Boosting Classifier model\n",
    "gradient_boosting_model = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model\n",
    "gradient_boosting_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_gradient_boosting = gradient_boosting_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gradient_boosting = accuracy_score(y_test, y_pred_gradient_boosting)\n",
    "print(f'Gradient Boosting Classifier Accuracy: {accuracy_gradient_boosting:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original dataset: (45211, 35)\n",
      "Shape of cleaned dataset: (40210, 35)\n",
      "we loss: 11.06% from the data\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(r\"C:\\Users\\plahare\\Downloads\\Numora_Demo\\archive (2)\\train.csv\", sep=\";\")\n",
    "train_df.rename(columns={'y': 'deposit'}, inplace=True)\n",
    "\n",
    "# Define categorical features\n",
    "categorical_to_onehot = ['job', 'marital', 'contact', 'poutcome']\n",
    "categorical_to_labelencoder = [\"education\", \"housing\", \"deposit\", \"default\", \"loan\", \"month\"]\n",
    "\n",
    "# Encode categorical features using OneHotEncoder\n",
    "new_df = train_df.copy()\n",
    "for i in categorical_to_onehot:\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(new_df[[i]])\n",
    "    onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out([i]))\n",
    "    new_df = pd.concat([new_df, onehot_encoded_df], axis=1)\n",
    "\n",
    "train_df = new_df.copy()\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "for categorical_label in categorical_to_labelencoder:\n",
    "    train_df[categorical_label] = encoder.fit_transform(train_df[categorical_label])\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['job', 'marital', 'contact', 'poutcome']\n",
    "\n",
    "# Create new_data by dropping the specified columns\n",
    "train_df = train_df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Function to remove outliers\n",
    "def remove_outliers(data, numerical_features, threshold=3):\n",
    "    z_scores = data[numerical_features].apply(zscore)\n",
    "    outlier_indices = (z_scores > threshold).any(axis=1)\n",
    "    cleaned_df = data[~outlier_indices]\n",
    "    return cleaned_df\n",
    "\n",
    "# Usage example:\n",
    "cleaned_df = remove_outliers(train_df, numerical_features)\n",
    "print(\"Shape of original dataset:\", train_df.shape)\n",
    "print(\"Shape of cleaned dataset:\", cleaned_df.shape)\n",
    "prc = ((train_df.shape[0] - cleaned_df.shape[0]) /train_df.shape[0]) *100\n",
    "print(f'we loss: {round(prc,2)}% from the data')\n",
    "\n",
    "# Extract features and target variable\n",
    "X = cleaned_df.drop('deposit', axis=1)\n",
    "y = cleaned_df['deposit'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test_scaled = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Initialize Random Forest model\n",
    "random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# Train the Random Forest model\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save Random Forest model with MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(random_forest_model, \"random_forest_model\")\n",
    "    random_forest_model_uri = f\"runs:/{run.info.run_id}/random_forest_model\"\n",
    "\n",
    "# Save Gradient Boosting model with MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(gradient_boosting_model, \"gradient_boosting_model\")\n",
    "    gradient_boosting_model_uri = f\"runs:/{run.info.run_id}/gradient_boosting_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Get current username\n",
    "model_creator = os.getlogin()\n",
    "\n",
    "# Get MLflow run creation time\n",
    "creation_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Start main MLflow run\n",
    "with mlflow.start_run() as main_run:\n",
    "    # Load Random Forest model\n",
    "    random_forest_model = mlflow.sklearn.load_model(random_forest_model_uri)\n",
    "    \n",
    "    # Start nested run for Random Forest model\n",
    "    with mlflow.start_run(run_name=\"Random Forest\", nested=True):\n",
    "        # Log metadata for Random Forest model\n",
    "        mlflow.log_param(\"ModelName\", \"Random Forest\")\n",
    "        mlflow.log_param(\"ModelType\", \"Classification\")\n",
    "        mlflow.log_param(\"ModelCreationDate\", creation_time)\n",
    "        mlflow.log_param(\"ModelCreator\", model_creator)\n",
    "        mlflow.log_param(\"ModelLatestVersion\", \"1\")  # Change this to the actual version\n",
    "        mlflow.log_param(\"ModelParameters\", str(random_forest_model.get_params()))\n",
    "        mlflow.log_param(\"ModelEnvironment\", \"Production\")\n",
    "    \n",
    "    # Load Gradient Boosting model\n",
    "    gradient_boosting_model = mlflow.sklearn.load_model(gradient_boosting_model_uri)\n",
    "    \n",
    "    # Start nested run for Gradient Boosting model\n",
    "    with mlflow.start_run(run_name=\"Gradient Boosting\", nested=True):\n",
    "        # Log metadata for Gradient Boosting model\n",
    "        mlflow.log_param(\"ModelName\", \"Gradient Boosting\")\n",
    "        mlflow.log_param(\"ModelType\", \"Classification\")\n",
    "        mlflow.log_param(\"ModelCreationDate\", creation_time)\n",
    "        mlflow.log_param(\"ModelCreator\", model_creator)\n",
    "        mlflow.log_param(\"ModelLatestVersion\", \"1\")  # Change this to the actual version\n",
    "        mlflow.log_param(\"ModelParameters\", str(gradient_boosting_model.get_params()))\n",
    "        mlflow.log_param(\"ModelEnvironment\", \"Production\")\n",
    "\n",
    "    # Extract metadata and create DataFrame\n",
    "    metadata = {\n",
    "        'ModelName': [\"Random Forest\", \"Gradient Boosting\"],\n",
    "        'ModelType': [\"Classification\", \"Classification\"],\n",
    "        'ModelCreationDate': [creation_time, creation_time],\n",
    "        'ModelCreator': [model_creator, model_creator],\n",
    "        'ModelLatestVersion': [\"1\", \"1\"],  # Change this to the actual version\n",
    "        'ModelParameters': [random_forest_model.get_params(), gradient_boosting_model.get_params()],\n",
    "        'ModelEnvironment': [\"Production\", \"Production\"]\n",
    "    }\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "    # Save metadata to CSV\n",
    "    metadata_df.to_csv(\"model_metadata_updated.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
